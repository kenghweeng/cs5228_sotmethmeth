{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gradient boosting\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('cs5228_finalproject/df_train_new.csv')\n",
    "df_val = pd.read_csv('cs5228_finalproject/df_val_new.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_full_train = pd.concat([df_train, df_val[df_train.columns]], axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['workclass', 'education', 'occupation', 'native-country']\n",
    "float_cols = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "value_dict = {}\n",
    "col_ordering = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_test, y_pred):\n",
    "    return round(f1_score(y_test, y_pred, average='weighted') * 100, 2)\n",
    "\n",
    "def acc(y_test, y_pred):\n",
    "    return round(accuracy_score(y_test, y_pred) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.cols = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        temp_x = X\n",
    "        for col in self.cols:\n",
    "            le = LabelEncoder()\n",
    "            temp = pd.DataFrame(le.fit_transform(temp_x[col]), columns = [col])\n",
    "            temp_x = pd.concat([temp_x.drop([col], axis = 1), temp], axis = 1)\n",
    "        return temp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping for education\n",
    "before_hs = [' 12th', ' 10th', ' 9th', ' 5th-6th', ' 11th', ' 7th-8th', ' 1st-4th', ' Preschool']\n",
    "assoc = [' Assoc-voc', ' Assoc-acdm']\n",
    "post_grad = [' Masters', ' Doctorate', ' Prof-school']\n",
    "\n",
    "# Grouping for workclass\n",
    "govt = [' State-gov', ' Local-gov', ' Federal-gov']\n",
    "others = [' ?', ' Never-worked', ' Without-pay']\n",
    "\n",
    "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        temp_x = X\n",
    "        \n",
    "        temp_x.replace(' ?', 'others')\n",
    "        # Feature Engineering - creating investor column which is 1 if there is any capital-gain or capital-loss\n",
    "        temp_x['investor'] = 0\n",
    "        temp_x.loc[temp_x[temp_x['capital-gain'] != temp_x['capital-gain'].min()].index, 'investor'] = 1\n",
    "        temp_x.loc[temp_x[temp_x['capital-loss'] != temp_x['capital-loss'].min()].index, 'investor'] = 1\n",
    "        \n",
    "        # Feature Engineering - grouping education\n",
    "        temp_x.loc[temp_x[temp_x['education'].isin(before_hs)].index, 'education'] = 'before-hs'\n",
    "        temp_x.loc[temp_x[temp_x['education'].isin(assoc)].index, 'education'] = 'assoc'\n",
    "        temp_x.loc[temp_x[temp_x['education'].isin(post_grad)].index, 'education'] = 'post_grad'\n",
    "        \n",
    "        # Feature Engineering - grouping marital-status column\n",
    "        temp_x['marital-status'] = temp_x['marital-status'].map({' Never-married': 'Single', ' Divorced': 'Single', \n",
    "                                                       ' Married-civ-spouse': 'Married', ' Married-spouse-absent': 'Married', \n",
    "                                                       ' Married-AF-spouse': 'Married', ' Never-married': 'Single', \n",
    "                                                       ' Separated': 'Single', ' Widowed': 'Single'})\n",
    "        \n",
    "        # Feature Engineering - grouping workclass column\n",
    "        temp_x.loc[temp_x[temp_x['workclass'].isin(govt)].index, 'workclass'] = 'govt'\n",
    "        temp_x.loc[temp_x[temp_x['workclass'].isin(others)].index, 'workclass'] = 'others'\n",
    "        return temp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.cols = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        temp_x = X\n",
    "        return temp_x.drop(self.cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clean(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, set_value_dict=False):\n",
    "        self.set_value_dict = set_value_dict\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if (self.set_value_dict):\n",
    "            for col in X.columns:\n",
    "                global value_dict\n",
    "                value_dict[col] = X[col].unique()\n",
    "            return X\n",
    "        else:\n",
    "            for col in categorical_cols:\n",
    "                for i in range(len(X[col])):\n",
    "                    if X.loc[i, col] not in value_dict[col]:\n",
    "                        X.loc[i, col] = 'others'\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in categorical columns\n",
    "class GetDummies(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cat_columns, float_columns, get_columns=False):\n",
    "        self.cat_columns = cat_columns\n",
    "        self.float_columns = float_columns\n",
    "        self.get_columns = get_columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        temp_x = X\n",
    "        for col in temp_x.columns:\n",
    "            if col in self.cat_columns:\n",
    "                temp_x[col] = temp_x[col].astype('category')\n",
    "            elif col in self.float_columns:\n",
    "                temp_x[col] = temp_x[col].astype('float64')\n",
    "            else:\n",
    "                temp_x[col] = temp_x[col].astype('int64')\n",
    "        dummies = pd.get_dummies(temp_x)\n",
    "        if self.get_columns:\n",
    "            global col_ordering\n",
    "            col_ordering = dummies.columns\n",
    "        return dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, set_columns=False):\n",
    "        self.set_columns = set_columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if self.set_columns:\n",
    "            for col in col_ordering:\n",
    "                if col not in X.columns:\n",
    "                    X[col] = 0\n",
    "            return X[col_ordering]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_train = Pipeline([\n",
    "    ('feature_engineering', FeatureEngineering()),\n",
    "    ('gender_transformer', LabelEncoderTransformer(['sex', 'marital-status'])),\n",
    "    ('drop_features', DropFeatures(['education-num', 'relationship'])),\n",
    "    ('clean', Clean(set_value_dict=True)),\n",
    "    ('get_dummies', GetDummies(categorical_cols, float_cols, get_columns = True)),\n",
    "    ('set_features', SetFeatures())\n",
    "])\n",
    "\n",
    "df_train = pp_train.fit_transform(df_train)\n",
    "df_train_y = df_train['class']\n",
    "df_train_x = df_train.drop('class', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_test = Pipeline([\n",
    "    ('feature_engineering', FeatureEngineering()),\n",
    "    ('gender_transformer', LabelEncoderTransformer(['sex', 'marital-status'])),\n",
    "    ('drop_features', DropFeatures(['education-num', 'relationship'])),\n",
    "    ('clean', Clean()),\n",
    "    ('get_dummies', GetDummies(categorical_cols, float_cols)),\n",
    "    ('set_features', SetFeatures(set_columns=True))\n",
    "])\n",
    "df_val = pp_test.fit_transform(df_val)\n",
    "df_val_y = df_val['class']\n",
    "df_val_x = df_val.drop('class', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pp_test.fit_transform(df_test)\n",
    "df_test_y = df_test['class']\n",
    "df_test_x = df_test.drop('class', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 22.3min\n",
      "[Parallel(n_jobs=4)]: Done 960 out of 960 | elapsed: 27.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=5228, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.1, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_...\n",
       "                                     random_state=5228, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     silent=True, subsample=None,\n",
       "                                     tree_method=None,\n",
       "                                     validate_parameters=False,\n",
       "                                     verbosity=None),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'gamma': [0.1, 0.5, 1, 1.5, 2, 5, 7, 9],\n",
       "                         'max_depth': [3, 4, 5, 6],\n",
       "                         'min_child_weight': [1, 5, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_weighted', verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.1, 0.5, 1, 1.5, 2, 5, 7, 9],\n",
    "        'max_depth': [3,4, 5, 6]\n",
    "        }\n",
    "\n",
    "folds = 10\n",
    "param_comb = 5\n",
    "\n",
    "xgbc = XGBClassifier(objective='binary:logistic',silent=True, nthread=1, random_state=5228, learning_rate = 0.1)\n",
    "kf = StratifiedKFold(n_splits=10, random_state=5228, shuffle=True)\n",
    "clf = GridSearchCV(xgbc, params, cv=kf, scoring='f1_weighted', verbose = 1, n_jobs=4)\n",
    "clf.fit(df_train_x, df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.4\n",
      "87.83\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgbc = clf.predict(df_val_x)\n",
    "print(f1(df_val_y, y_pred_xgbc))\n",
    "print(acc(df_val_y, y_pred_xgbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining with full train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_dict = {}\n",
    "col_ordering = []\n",
    "\n",
    "pp_train = Pipeline([\n",
    "    ('feature_engineering', FeatureEngineering()),\n",
    "    ('gender_transformer', LabelEncoderTransformer(['sex', 'marital-status'])),\n",
    "    ('drop_features', DropFeatures(['education-num', 'relationship'])),\n",
    "    ('clean', Clean(set_value_dict=True)),\n",
    "    ('get_dummies', GetDummies(categorical_cols, float_cols, get_columns = True)),\n",
    "    ('set_features', SetFeatures())\n",
    "])\n",
    "\n",
    "df_full_train = pp_train.fit_transform(df_full_train)\n",
    "df_full_train_y = df_full_train['class']\n",
    "df_full_train_x = df_full_train.drop('class', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_test = Pipeline([\n",
    "    ('feature_engineering', FeatureEngineering()),\n",
    "    ('gender_transformer', LabelEncoderTransformer(['sex', 'marital-status'])),\n",
    "    ('drop_features', DropFeatures(['education-num', 'relationship'])),\n",
    "    ('clean', Clean()),\n",
    "    ('get_dummies', GetDummies(categorical_cols, float_cols)),\n",
    "    ('set_features', SetFeatures(set_columns=True))\n",
    "])\n",
    "\n",
    "df_test = pp_test.fit_transform(df_test)\n",
    "df_test_y = df_test['class']\n",
    "df_test_x = df_test.drop('class', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_new = XGBClassifier(objective='binary:logistic',silent=True, nthread=1, random_state=5228, learning_rate = 0.1)\n",
    "xgbc_new.set_params(**clf.best_params_)\n",
    "xgbc_new.fit(df_full_train_x, df_full_train_y)\n",
    "\n",
    "xgbc_new_pred = xgbc_new.predict(df_test_x)\n",
    "output_df = pd.DataFrame({'id': [i+1 for i in range(len(xgbc_new_pred))], 'prediction': xgbc_new_pred})\n",
    "output_df.to_csv('predictions_xgbc_' + datetime.now().strftime('%d%m%y') + '_all.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
