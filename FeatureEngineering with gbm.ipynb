{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gradient boosting\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('cs5228_finalproject/df_train_v2.csv')\n",
    "df_val = pd.read_csv('cs5228_finalproject/df_val_v2.csv')\n",
    "df_test = pd.read_csv('cs5228_finalproject/df_test_new.csv')\n",
    "df_full_train = pd.concat([df_train, df_val[df_train.columns]], axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['workclass', 'education', 'occupation', 'native-country']\n",
    "float_cols = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "value_dict = {}\n",
    "col_ordering = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_test, y_pred):\n",
    "    return round(f1_score(y_test, y_pred, average='weighted') * 100, 2)\n",
    "\n",
    "def acc(y_test, y_pred):\n",
    "    return round(accuracy_score(y_test, y_pred) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.cols = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        temp_x = X\n",
    "        for col in self.cols:\n",
    "            le = LabelEncoder()\n",
    "            temp = pd.DataFrame(le.fit_transform(temp_x[col]), columns = [col])\n",
    "            temp_x = pd.concat([temp_x.drop([col], axis = 1), temp], axis = 1)\n",
    "        return temp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping for education\n",
    "before_hs = [' 12th', ' 10th', ' 9th', ' 5th-6th', ' 11th', ' 7th-8th', ' 1st-4th', ' Preschool']\n",
    "assoc = [' Assoc-voc', ' Assoc-acdm']\n",
    "post_grad = [' Masters', ' Doctorate', ' Prof-school']\n",
    "\n",
    "# Grouping for workclass\n",
    "govt = [' State-gov', ' Local-gov', ' Federal-gov']\n",
    "others = [' ?', ' Never-worked', ' Without-pay']\n",
    "\n",
    "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        temp_x = X\n",
    "        \n",
    "        temp_x.replace(' ?', 'others')\n",
    "        # Feature Engineering - creating investor column which is 1 if there is any capital-gain or capital-loss\n",
    "        temp_x['investor'] = 0\n",
    "        temp_x.loc[temp_x[temp_x['capital-gain'] != temp_x['capital-gain'].min()].index, 'investor'] = 1\n",
    "        temp_x.loc[temp_x[temp_x['capital-loss'] != temp_x['capital-loss'].min()].index, 'investor'] = 1\n",
    "        \n",
    "        # Feature Engineering - grouping education\n",
    "        temp_x.loc[temp_x[temp_x['education'].isin(before_hs)].index, 'education'] = 'before-hs'\n",
    "        temp_x.loc[temp_x[temp_x['education'].isin(assoc)].index, 'education'] = 'assoc'\n",
    "        temp_x.loc[temp_x[temp_x['education'].isin(post_grad)].index, 'education'] = 'post_grad'\n",
    "        \n",
    "        # Feature Engineering - grouping marital-status column\n",
    "        temp_x['marital-status'] = temp_x['marital-status'].map({' Never-married': 'Single', ' Divorced': 'Single', \n",
    "                                                       ' Married-civ-spouse': 'Married', ' Married-spouse-absent': 'Married', \n",
    "                                                       ' Married-AF-spouse': 'Married', ' Never-married': 'Single', \n",
    "                                                       ' Separated': 'Single', ' Widowed': 'Single'})\n",
    "        \n",
    "        # Feature Engineering - grouping workclass column\n",
    "        temp_x.loc[temp_x[temp_x['workclass'].isin(govt)].index, 'workclass'] = 'govt'\n",
    "        temp_x.loc[temp_x[temp_x['workclass'].isin(others)].index, 'workclass'] = 'others'\n",
    "        return temp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.cols = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        temp_x = X\n",
    "        return temp_x.drop(self.cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clean(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, set_value_dict=False):\n",
    "        self.set_value_dict = set_value_dict\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if (self.set_value_dict):\n",
    "            for col in X.columns:\n",
    "                global value_dict\n",
    "                value_dict[col] = X[col].unique()\n",
    "            return X\n",
    "        else:\n",
    "            for col in categorical_cols:\n",
    "                for i in range(len(X[col])):\n",
    "                    if X.loc[i, col] not in value_dict[col]:\n",
    "                        X.loc[i, col] = 'others'\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in categorical columns\n",
    "class GetDummies(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cat_columns, float_columns, get_columns=False):\n",
    "        self.cat_columns = cat_columns\n",
    "        self.float_columns = float_columns\n",
    "        self.get_columns = get_columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        temp_x = X\n",
    "        for col in temp_x.columns:\n",
    "            if col in self.cat_columns:\n",
    "                temp_x[col] = temp_x[col].astype('category')\n",
    "            elif col in self.float_columns:\n",
    "                temp_x[col] = temp_x[col].astype('float64')\n",
    "            else:\n",
    "                temp_x[col] = temp_x[col].astype('int64')\n",
    "        dummies = pd.get_dummies(temp_x)\n",
    "        if self.get_columns:\n",
    "            global col_ordering\n",
    "            col_ordering = dummies.columns\n",
    "        return dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, set_columns=False):\n",
    "        self.set_columns = set_columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if self.set_columns:\n",
    "            for col in col_ordering:\n",
    "                if col not in X.columns:\n",
    "                    X[col] = 0\n",
    "            return X[col_ordering]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_train = Pipeline([\n",
    "    ('feature_engineering', FeatureEngineering()),\n",
    "    ('gender_transformer', LabelEncoderTransformer(['sex', 'marital-status'])),\n",
    "    ('drop_features', DropFeatures(['education-num', 'relationship'])),\n",
    "    ('clean', Clean(set_value_dict=True)),\n",
    "    ('get_dummies', GetDummies(categorical_cols, float_cols, get_columns = True)),\n",
    "    ('set_features', SetFeatures())\n",
    "])\n",
    "\n",
    "df_train = pp_train.fit_transform(df_train)\n",
    "df_train_y = df_train['class']\n",
    "df_train_x = df_train.drop('class', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_test = Pipeline([\n",
    "    ('feature_engineering', FeatureEngineering()),\n",
    "    ('gender_transformer', LabelEncoderTransformer(['sex', 'marital-status'])),\n",
    "    ('drop_features', DropFeatures(['education-num', 'relationship'])),\n",
    "    ('clean', Clean()),\n",
    "    ('get_dummies', GetDummies(categorical_cols, float_cols)),\n",
    "    ('set_features', SetFeatures(set_columns=True))\n",
    "])\n",
    "df_val = pp_test.fit_transform(df_val)\n",
    "df_val_y = df_val['class']\n",
    "df_val_x = df_val.drop('class', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pp_test.fit_transform(df_test)\n",
    "df_test_y = df_test['class']\n",
    "df_test_x = df_test.drop('class', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 56 candidates, totalling 560 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=4)]: Done 560 out of 560 | elapsed: 16.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=5228, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                                  criterion='friedman_mse',\n",
       "                                                  init=None, learning_rate=0.1,\n",
       "                                                  loss='deviance', max_depth=3,\n",
       "                                                  max_features=None,\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2...\n",
       "                                                  n_iter_no_change=None,\n",
       "                                                  presort='deprecated',\n",
       "                                                  random_state=5228,\n",
       "                                                  subsample=1.0, tol=0.0001,\n",
       "                                                  validation_fraction=0.1,\n",
       "                                                  verbose=0, warm_start=True),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'loss': ['deviance', 'exponential'],\n",
       "                         'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
       "                         'min_samples_leaf': [5, 6, 7, 8]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_weighted', verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'loss': ['deviance', 'exponential'],\n",
    "              'min_samples_leaf': [5, 6, 7, 8],\n",
    "              'max_depth': [i for i in range(3,10,1)],\n",
    "             }\n",
    "gbm = GradientBoostingClassifier(warm_start=True, random_state=5228)\n",
    "kf = StratifiedKFold(n_splits=10, random_state=5228, shuffle=True)\n",
    "clf = GridSearchCV(gbm, parameters, cv=kf, scoring='f1_weighted', verbose = 1, n_jobs = 4)\n",
    "clf.fit(df_train_x, df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.05\n",
      "86.6\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgbc = clf.predict(df_val_x)\n",
    "print(f1(df_val_y, y_pred_xgbc))\n",
    "print(acc(df_val_y, y_pred_xgbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining with full train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_dict = {}\n",
    "col_ordering = []\n",
    "\n",
    "pp_train = Pipeline([\n",
    "    ('feature_engineering', FeatureEngineering()),\n",
    "    ('gender_transformer', LabelEncoderTransformer(['sex', 'marital-status'])),\n",
    "    ('drop_features', DropFeatures(['education-num', 'relationship'])),\n",
    "    ('clean', Clean(set_value_dict=True)),\n",
    "    ('get_dummies', GetDummies(categorical_cols, float_cols, get_columns = True)),\n",
    "    ('set_features', SetFeatures())\n",
    "])\n",
    "\n",
    "df_full_train = pp_train.fit_transform(df_full_train)\n",
    "df_full_train_y = df_full_train['class']\n",
    "df_full_train_x = df_full_train.drop('class', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_new = GradientBoostingClassifier(warm_start=True, random_state=5228)\n",
    "gbm_new.set_params(**clf.best_params_)\n",
    "gbm_new.fit(df_full_train_x, df_full_train_y)\n",
    "\n",
    "gbm_new_pred = gbm_new.predict(df_test_x)\n",
    "output_df = pd.DataFrame({'id': [i+1 for i in range(len(gbm_new_pred))], 'prediction': gbm_new_pred})\n",
    "output_df.to_csv('predictions_gbm_' + datetime.now().strftime('%d%m%y') + '_all.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
